{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a46ff8-1aeb-40a9-ab2e-53dbddabbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import git\n",
    "import pathlib\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # use GPU\n",
    "# Using GPU during inference has deterministic results (same as CPU)\n",
    "\n",
    "PROJ_ROOT_PATH = pathlib.Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "PROJ_ROOT =  str(PROJ_ROOT_PATH)\n",
    "if PROJ_ROOT not in sys.path:\n",
    "    sys.path.append(PROJ_ROOT)\n",
    "\n",
    "from libs import utils, mnist32_cnn\n",
    "from libs.constants import model_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24272124-9be7-4c55-ba5a-a6dcbb471c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit GPU growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f854f283-e420-4f70-a699-b3b84b69d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "# Combine test and train images together into one dataset\n",
    "DATASET_PATH = str(pathlib.Path(PROJ_ROOT_PATH / \"datasets\" / \"mnist.npz\" ))\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data(path=DATASET_PATH)\n",
    "train_images = train_images.astype(np.float32) / 255.0\n",
    "test_images = test_images.astype(np.float32) / 255.0  \n",
    "\n",
    "all_images =np.concatenate([train_images, test_images], axis=0)\n",
    "all_labels =np.concatenate([train_labels, test_labels], axis=0)\n",
    "all_images = np.expand_dims(all_images, axis=-1)\n",
    "\n",
    "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
    "image_x_size = 32\n",
    "image_y_size = 32\n",
    "all_images = tf.image.resize(all_images, [image_x_size, image_y_size]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65d1c4c-9cb3-4c6f-9b42-606a0398d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"mnist32-cnn_1024_256_64\"\n",
    "model_seed = model_seeds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a08e97a-5f62-4d56-9c0c-10189004a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model\n",
    "model_instance = model_type + \"-\" + str(model_seed)\n",
    "dataset, model_arch, model_config, layer_widths, seed = utils.instancename2metadata(model_instance)\n",
    "model_meta_type, model_type, model_instance = utils.metadata2instancenames(dataset, model_arch, layer_widths, seed)\n",
    "\n",
    "model_folder = pathlib.Path(PROJ_ROOT_PATH / \"models\" / model_meta_type / model_type)\n",
    "model_filename = model_instance + \".h5\"\n",
    "model_file = pathlib.Path(model_folder/ model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bde2915-dff1-43e8-97c7-04880fa86289",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.expand_dims(all_images[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b99335f-83ef-41bc-985a-c30d7fd6bade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 32, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad148d51-7fe2-44ce-9c70-efa8eb5102e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 29, 29, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " fc_0 (Dense)                (None, 1024)              6423552   \n",
      "                                                                 \n",
      " fc_1 (Dense)                (None, 256)               262400    \n",
      "                                                                 \n",
      " fc_2 (Dense)                (None, 64)                16448     \n",
      "                                                                 \n",
      " op_layer (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,703,594\n",
      "Trainable params: 6,703,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = tf.keras.models.load_model(model_file)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa42fef3-d03b-48f7-ada9-0f75d181744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights and biases from model\n",
    "conv2d_kernels, conv2d_biases = model.get_layer(\"conv2d\").weights\n",
    "fc_0_weights, fc_0_biases = model.get_layer(\"fc_0\").weights\n",
    "fc_1_weights, fc_1_biases = model.get_layer(\"fc_1\").weights\n",
    "fc_2_weights, fc_2_biases = model.get_layer(\"fc_2\").weights\n",
    "op_layer_weights, op_layer_biases = model.get_layer(\"op_layer\").weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b8f092-96c5-44b9-9e55-279f07d77929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2d_kernels.shape, conv2d_biases.shape\n",
    "# fc_0_weights.shape, fc_0_biases.shape\n",
    "# fc_1_weights.shape, fc_1_biases.shape\n",
    "# fc_2_weights.shape, fc_2_biases.shape\n",
    "# op_layer_weights.shape, op_layer_biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "722755ac-3fab-4baa-a786-01b7e83144e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution layer\n",
    "## get dimension constants\n",
    "kr_ht, kr_wt, no_ch, no_kr = conv2d_kernels.shape\n",
    "\n",
    "im_ht = image_y_size\n",
    "im_wt = image_x_size\n",
    "no_im = 1\n",
    "\n",
    "y_ht = im_ht - kr_ht + 1\n",
    "y_wt = im_wt - kr_wt + 1\n",
    "\n",
    "no_of_patches = y_ht * y_wt\n",
    "patch_len     = kr_ht * kr_wt * no_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84737817-7485-4e63-b376-d8c67e3751b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract image patches\n",
    "patches = tf.image.extract_patches(images=image,\n",
    "                                 sizes=[1, kr_ht, kr_wt, 1],\n",
    "                                 strides=[1, 1, 1, 1],\n",
    "                                 rates=[1, 1, 1, 1],\n",
    "                                 padding='VALID')\n",
    "## flatten patches\n",
    "flat_patches = tf.reshape(patches, (no_im, no_of_patches, patch_len))\n",
    "## tranpose for matrix multiplication\n",
    "flat_patches = tf.transpose(flat_patches, (0,2,1))\n",
    "\n",
    "## flatten filter kernels\n",
    "### first reorder kernels by no. of output-kernels\n",
    "flat_kernels = tf.transpose(conv2d_kernels, perm=(3,0,1,2))\n",
    "flat_kernels = tf.reshape(flat_kernels, (no_kr, kr_ht*kr_wt*no_ch))\n",
    "flat_kernels = tf.broadcast_to(flat_kernels, (no_im, no_kr, kr_ht*kr_wt*no_ch))\n",
    "\n",
    "## perform matrix multiplication\n",
    "conv_out = tf.matmul(flat_kernels, flat_patches)\n",
    "conv_out = tf.transpose(conv_out, (0,2,1))\n",
    "conv_out = tf.reshape(conv_out, (no_im, y_ht,y_wt, no_kr))\n",
    "\n",
    "## Add bias\n",
    "conv_out = tf.nn.bias_add(conv_out, conv2d_biases)\n",
    "## ReLU\n",
    "conv_out = tf.nn.relu(conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a86c9fa-b1c3-4cc7-aeed-6b8874d7fb09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check for convolutional layer\n",
    "# tf_conv_out = tf.nn.conv2d(input=image,\n",
    "#                             filters=conv2d_kernels,\n",
    "#                             strides=[1,1,1,1],\n",
    "#                             padding=\"VALID\",\n",
    "#                             data_format='NHWC',\n",
    "#                             dilations=None,\n",
    "#                             name=None\n",
    "#                         )\n",
    "\n",
    "# # convolutional layer sanity check\n",
    "# tf_conv_layer_dummy = tf.keras.layers.Conv2D(32, (4, 4), \n",
    "#                                   activation='relu', \n",
    "#                                   input_shape=(32, 32, 1))\n",
    "# # get layer running\n",
    "# dummy_input = tf.random.normal((1,32,32,1))\n",
    "# tf_conv_layer_dummy(dummy_input);\n",
    "\n",
    "# # load the weights\n",
    "# tf_conv_layer_dummy.set_weights([conv2d_kernels, conv2d_biases])\n",
    "# # run the convolution, bias adding and relu\n",
    "# tf_conv_layer_out = tf_conv_layer_dummy(image);\n",
    "# # check if outputs match\n",
    "# tf.reduce_sum(conv_out-tf_conv_layer_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "444dce28-6101-468a-bc4c-2135d9817afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Max Pooling\n",
    "pool_out = tf.nn.max_pool(\n",
    "                        conv_out,\n",
    "                        ksize=[1, 2, 2, 1], #(batch_size, height, width, depth)\n",
    "                        strides=[1, 2, 2, 1], #(batch_size, height, width, depth)\n",
    "                        padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6895dfd2-20a8-47ac-8481-b7f6c960b0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 14, 14, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98bb6b7f-a753-4590-b401-81336cb41abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6272])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten\n",
    "flat_out = tf.reshape(pool_out, (no_im, -1) ) #[batch_size, flat_vec_size]\n",
    "flat_out.shape\n",
    "# # Tranpose for multiplication\n",
    "# flat_out = tf.transpose(flat_out, perm=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f187af75-b953-4bee-bba3-a0e347933761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity Check for flatten layer\n",
    "# flayer = tf.keras.layers.Flatten()\n",
    "# flayer(pool_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1eef6bd-741f-4dbb-8120-b5f00e66604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranpose input vector\n",
    "fc_0_in = tf.transpose(flat_out, perm=[1,0]) #[flat_vec_size, batch_size]\n",
    "# fc_0_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "730a0f55-1d35-4cc2-a3e6-9c1d841c3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose weight matrices\n",
    "fc_0_weights_tr = tf.transpose(fc_0_weights, perm=[1,0]) #[no_of_weights, flat_vec_size]\n",
    "# fc_0_weights_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21d7b700-2651-4d49-9cfe-a28fc78529c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply input with weights\n",
    "fc_0_mult_out = tf.linalg.matmul(fc_0_weights_tr, fc_0_in)\n",
    "# Add bias\n",
    "fc_0_bout = tf.add(fc_0_mult_out, tf.expand_dims(fc_0_biases,axis=1))\n",
    "# RelU\n",
    "fc_0_out = tf.nn.relu(fc_0_bout)\n",
    "# fc_0_out needs to be transposed again in fc_1_in\n",
    "# so although fc_0_out shape is not \"standard\", we output it as it is\n",
    "# fc_0_out = tf.transpose(fc_0_out, perm=[1,0]) #[batch_no, vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6532bde5-6ba0-4a47-aea6-63cf5bc9e139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0058de2-33be-4f77-bce8-b6aa8b764372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't tranpose fc_0_out to convert to fc_1_in\n",
    "# fc_1_in = tf.transpose(flat_out, perm=[1,0])\n",
    "fc_1_in = fc_0_out\n",
    "fc_1_weights_tr = tf.transpose(fc_1_weights, perm=[1,0])\n",
    "fc_1_mult_out = tf.linalg.matmul(fc_1_weights_tr, fc_1_in)\n",
    "fc_1_bout = tf.add(fc_1_mult_out, tf.expand_dims(fc_1_biases,axis=1))\n",
    "fc_1_out = tf.nn.relu(fc_1_bout)\n",
    "# fc_1_out needs to be transposed again in fc_2_in\n",
    "# so although fc_1_out shape is not \"standard\", we output it as it is\n",
    "# fc_1_out = tf.transpose(fc_1_out, perm=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ed7e5b4-c365-429c-8e93-7a5594d03936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't tranpose fc_1_out to convert to fc_2_in\n",
    "# fc_2_in = tf.transpose(fc_1_out, perm=[1,0])\n",
    "fc_2_in = fc_1_out\n",
    "fc_2_weights_tr = tf.transpose(fc_2_weights, perm=[1,0])\n",
    "fc_2_mult_out = tf.linalg.matmul(fc_2_weights_tr, fc_2_in)\n",
    "fc_2_bout = tf.add(fc_2_mult_out, tf.expand_dims(fc_2_biases,axis=1))\n",
    "fc_2_out = tf.nn.relu(fc_2_bout)\n",
    "# fc_2_out needs to be transposed again in op_layer_in\n",
    "# so although fc_2_out shape is not \"standard\", we output it as it is\n",
    "# fc_2_out = tf.transpose(fc_2_out, perm=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "956c1bd0-cba8-4596-836d-7b0938dff76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't tranpose fc_2_out to convert to op_layer_in\n",
    "# fc_2_in = tf.transpose(fc_1_out, perm=[1,0])\n",
    "op_layer_in = fc_2_out\n",
    "op_layer_weights_tr = tf.transpose(op_layer_weights, perm=[1,0])\n",
    "op_layer_mult_out = tf.linalg.matmul(op_layer_weights_tr, op_layer_in)\n",
    "op_layer_bout = tf.add(op_layer_mult_out, tf.expand_dims(op_layer_biases,axis=1))\n",
    "op_layer_out = tf.nn.relu(op_layer_bout)\n",
    "op_layer_out = tf.transpose(op_layer_out, perm=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2431bf3b-94ea-43a0-894e-b1bf88d24806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[ 0.       ,  0.       ,  0.       , 16.619106 ,  0.       ,\n",
       "        20.700577 ,  0.       ,  0.       ,  2.3377132,  5.1793656]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f5aa20f1-8e3d-4f06-808e-0cb9067417da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_scores = tf.nn.softmax(op_layer_out, axis=1)\n",
    "predictions = tf.math.argmax(class_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b943baaa-9634-49d3-a842-5e0096def3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[1.0059648e-09, 1.0059648e-09, 1.0059648e-09, 1.6602326e-02,\n",
       "        1.0059648e-09, 9.8339742e-01, 1.0059648e-09, 1.0059648e-09,\n",
       "        1.0419305e-08, 1.7862921e-07]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4b7031c-c514-419e-bdb6-4d88aa2f1cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([5])>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2866bd13-d7cf-4a68-acc9-b34e9a70e594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "511e7f4f-63be-48c0-a21f-30669c977639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity Check for dense layer\n",
    "# tf_dense_layer_dummy = tf.keras.layers.Dense(1024, activation=\"relu\")\n",
    "# # build layer\n",
    "# tf_dense_layer_dummy.build(input_shape=(flat_out.shape[-1],))\n",
    "# # load the weights\n",
    "# tf_dense_layer_dummy.set_weights([fc_0_weights, fc_0_biases])\n",
    "\n",
    "# # Implement the layer\n",
    "# tf_dense_out = tf_dense_layer_dummy(flat_out)\n",
    "# # tf_dense_out.shape\n",
    "\n",
    "# # Check if results match\n",
    "# tf.reduce_max(tf.abs(fc_0_out - tf_dense_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5449378f-2660-40ff-8eb4-93208295bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_fc_layers = 1 #initalized to 1 to account for output layer\n",
    "for layer in model.layers:\n",
    "    if layer.name.startswith(\"fc\"):\n",
    "        no_of_fc_layers += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c27d82b9-bfe1-4186-8375-29d215b1d223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_fc_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4109ef-071f-4924-a29f-8372c3c20dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddb31c-fced-4790-89e3-005c27c0c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fc layer\n",
    "# fc_in\n",
    "# fc_bias = tf.reshape(fc_bias,(-1,1)) # for broadcasting\n",
    "# # multiply with weights\n",
    "# fc_mult_out = tf.linalg.matmul(fc_0_weights, fc_in, transposea=true)\n",
    "# # add bias\n",
    "# fc_bout = fc_mult_out + fc_bias\n",
    "# # RelU\n",
    "# fc_out = tf.nn.relu(fc_bout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d09554-aa7e-42d1-8a73-0c315f70302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fully connected layer - 7*7*64 to 1024\n",
    "# fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "# fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "# fc1 = tf.nn.relu(fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d40c2f-bcd1-4bb7-818a-90f1f2203636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53aa689-dd29-4c39-b76d-840f35a44c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_fitness(model)\n",
    "# eval_lenet_3hidden_errexpbitflip(model,\n",
    "#                                 error_profile_c0,\n",
    "#                                 error_profile_h0,\n",
    "#                                 error_profile_h1,\n",
    "#                                 error_profile_h2,\n",
    "#                                 error_profile_op,\n",
    "#                                 ERR_PARAM,\n",
    "#                                 clayer0_shuffle_order,\n",
    "#                                 hlayer0_shuffle_order,\n",
    "#                                 hlayer1_shuffle_order,\n",
    "#                                 hlayer2_shuffle_order,\n",
    "#                                 oplayer_shuffle_order,\n",
    "#                                 test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ac77f-60e2-4420-9a7e-dca245a0727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ff_dense_alllayer_2hidden_ERRexpbitflips(model, \n",
    "#                                         error_profile_c0,\n",
    "#                                         error_profile_h0,\n",
    "#                                         error_profile_h1,\n",
    "#                                         error_profile_h2,\n",
    "#                                         error_profile_op,\n",
    "#                                         ERR_PARAM,\n",
    "#                                         clayer0_shuffle_order,\n",
    "#                                         hlayer0_shuffle_order,\n",
    "#                                         hlayer1_shuffle_order,\n",
    "#                                         hlayer2_shuffle_order,\n",
    "#                                         oplayer_shuffle_order,\n",
    "#                                         test_set, \n",
    "#                                         batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190b8e1-5103-4173-8379-5cde99eb1337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d68a8-67a6-4243-ad20-9867232858cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7174b-a91d-4ac1-b3ad-48218c24db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[accuracy, conf_matrix] = mnist32_cnn.test_mnist32(model_file, show_summary=False)\n",
    "print(f\"Model: {model_instance} \\t Accuracy:{accuracy*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49674c-0df3-43d7-842b-9b7f3329c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mnist32(model_file, show_summary=False):\n",
    "\n",
    "    # Prepare dataset\n",
    "    # Combine test and train images together into one dataset\n",
    "    DATASET_PATH = str(pathlib.Path(PROJ_ROOT_PATH / \"datasets\" / \"mnist.npz\" ))\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data(path=DATASET_PATH)\n",
    "    train_images = train_images.astype(np.float32) / 255.0\n",
    "    test_images = test_images.astype(np.float32) / 255.0  \n",
    "\n",
    "    all_images =np.concatenate([train_images, test_images], axis=0)\n",
    "    all_labels =np.concatenate([train_labels, test_labels], axis=0)\n",
    "    all_images = np.expand_dims(all_images, axis=-1)\n",
    "    \n",
    "    # resize the input shape , i.e. old shape: 28, new shape: 32\n",
    "    image_x_size = 32\n",
    "    image_y_size = 32\n",
    "    all_images = tf.image.resize(all_images, [image_x_size, image_y_size]) \n",
    "\n",
    "    # Load model\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(all_images) # Predict encoded label as 2 => [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    Y_pred = np.argmax(y_pred, 1) # Decode Predicted labels\n",
    "\n",
    "    accuracy = accuracy_score(y_true=all_labels, y_pred=Y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true=all_labels, y_pred=Y_pred) \n",
    "          \n",
    "    return [accuracy, conf_matrix]\n",
    "\n",
    "#############################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
