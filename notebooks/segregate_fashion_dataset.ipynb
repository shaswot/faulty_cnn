{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d298b2d1-f9ad-4c29-a481-0ea010f1f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import git\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "PROJ_ROOT_PATH = pathlib.Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "PROJ_ROOT =  str(PROJ_ROOT_PATH)\n",
    "if PROJ_ROOT not in sys.path:\n",
    "    sys.path.append(PROJ_ROOT)\n",
    "    \n",
    "from libs.utils import segregate_dataset_4Q_mean\n",
    "from libs.utils import segregate_dataset_4Q_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c1fb46-9363-4d81-9e42-312299b28a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.astype(np.float32) / 255.0\n",
    "test_images = test_images.astype(np.float32) / 255.0\n",
    "\n",
    "all_images =np.concatenate([train_images, test_images], axis=0)\n",
    "all_labels =np.concatenate([train_labels, test_labels], axis=0)\n",
    "all_images = np.expand_dims(all_images, axis=-1)\n",
    "\n",
    "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
    "image_x_size = 28\n",
    "image_y_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a85a587-c5d4-43a0-8fbe-5b2b7b772ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_num = 128 * 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0509ec-c60f-4f6b-bb34-b65527d418c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiate images into4 types using mean\n",
    "# Use mostly test images but add from train images to\n",
    "# make the size = im_num\n",
    "\n",
    "(qmean1_images, qmean1_labels,\n",
    "qmean2_images, qmean2_labels,\n",
    "qmean3_images, qmean3_labels,\n",
    "qmean4_images, qmean4_labels) = segregate_dataset_4Q_mean(all_images, all_labels, half_size=int(image_x_size/2))\n",
    "\n",
    "qmean1_images = qmean1_images[-im_num:]\n",
    "qmean1_labels = qmean1_labels[-im_num:]\n",
    "\n",
    "qmean2_images = qmean2_images[-im_num:]\n",
    "qmean2_labels = qmean2_labels[-im_num:]\n",
    "\n",
    "qmean3_images = qmean3_images[-im_num:]\n",
    "qmean3_labels = qmean3_labels[-im_num:]\n",
    "\n",
    "qmean4_images = qmean4_images[-im_num:]\n",
    "qmean4_labels = qmean4_labels[-im_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db4c2485-208d-421f-ac74-23d21bab9908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120, 5120, 5120, 5120)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(qmean1_labels),len(qmean2_labels),len(qmean3_labels),len(qmean4_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "039b329c-d6c0-4257-a106-29bea23d0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiate images into4 types using entropy\n",
    "# Use mostly test images but add from train images to\n",
    "# make the size = im_num\n",
    "\n",
    "(qent1_images, qent1_labels,\n",
    "qent2_images, qent2_labels,\n",
    "qent3_images, qent3_labels,\n",
    "qent4_images, qent4_labels) = segregate_dataset_4Q_ent(all_images, all_labels, half_size=int(image_x_size/2))\n",
    "\n",
    "qent1_images = qent1_images[-im_num:]\n",
    "qent1_labels = qent1_labels[-im_num:]\n",
    "\n",
    "qent2_images = qent2_images[-im_num:]\n",
    "qent2_labels = qent2_labels[-im_num:]\n",
    "\n",
    "qent3_images = qent3_images[-im_num:]\n",
    "qent3_labels = qent3_labels[-im_num:]\n",
    "\n",
    "qent4_images = qent4_images[-im_num:]\n",
    "qent4_labels = qent4_labels[-im_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dde6d3c-d1fa-45d9-ac52-a3c146b935b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120, 5120, 5120, 5120)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(qent1_labels),len(qent2_labels),len(qent3_labels),len(qent4_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac7ee4-495d-4943-9355-8ba6635c7548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
