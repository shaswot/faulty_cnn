{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5797961-aa44-4c0b-a16a-fed2014dc068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import git\n",
    "import pathlib\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "PROJ_ROOT_PATH = pathlib.Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "PROJ_ROOT =  str(PROJ_ROOT_PATH)\n",
    "if PROJ_ROOT not in sys.path:\n",
    "    sys.path.append(PROJ_ROOT)\n",
    "\n",
    "from libs import utils, mnist32_cnn\n",
    "from libs.constants import model_seeds\n",
    "from libs.errmatmul import matmul_ERR, N_THREADS_PER_BLOCK\n",
    "from libs.fitnessfns import NO_OF_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d5dc02-f4b6-404e-98b3-b51897f9103f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Limit GPU growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09541d0b-5433-4d1c-8e52-498d37a93b49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load dataset  \n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c24870c-a06e-4e8d-b210-c7ae215260ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = \"fashion-cnn2_1024\"\n",
    "model_seed = model_seeds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475c3bf3-914b-4357-9f69-296b8cc63134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_instance = model_type + \"-\" + str(model_seed)\n",
    "model_folder = pathlib.Path(PROJ_ROOT_PATH / \"models\" / model_type)\n",
    "model_filename = model_instance + \".h5\"\n",
    "model_file = str(pathlib.Path(model_folder/ model_filename))\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf90000-81d5-4afc-a268-ef7b643710a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c482d142-3796-4cde-8c37-a7de80f4629b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = test_images[0:64]\n",
    "labels = test_labels[0:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20debcd5-d4d8-4d8c-baa1-eb67b60193bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_c0_out = model.layers[0](images)\n",
    "\n",
    "tf_p0_out = model.layers[1](\n",
    "                    model.layers[0](images))\n",
    "\n",
    "tf_c1_out = model.layers[3](\n",
    "                    model.layers[1](\n",
    "                        model.layers[0](images)))\n",
    "\n",
    "tf_p1_out = model.layers[4](\n",
    "                    model.layers[3](\n",
    "                        model.layers[1](\n",
    "                            model.layers[0](images))))\n",
    "\n",
    "tf_flatten_out = model.layers[6](\n",
    "                    model.layers[4](\n",
    "                        model.layers[3](\n",
    "                            model.layers[1](\n",
    "                                model.layers[0](images)))))\n",
    "tf_h0_out = model.layers[7](model.layers[6](\n",
    "                                model.layers[4](\n",
    "                                    model.layers[3](\n",
    "                                        model.layers[1](\n",
    "                                            model.layers[0](images))))))\n",
    "\n",
    "tf_op_out = model.layers[9](model.layers[7](\n",
    "                                model.layers[6](\n",
    "                                    model.layers[4](\n",
    "                                        model.layers[3](\n",
    "                                            model.layers[1](\n",
    "                                                model.layers[0](images)))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b598c523-6ff1-4a9a-9ff7-c158a3b299c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf_c0_out.shape\n",
    "\n",
    "# tf_p0_out.shape\n",
    "\n",
    "# tf_c1_out.shape\n",
    "\n",
    "# tf_p1_out.shape\n",
    "\n",
    "# tf_flatten_out.shape\n",
    "\n",
    "# tf_h0_out.shape\n",
    "\n",
    "# tf_op_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee8c9248-a72e-4ace-bf84-394ec26dcb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(images) # = tf_op_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39769f5a-71c6-4867-9aa7-ebee978697c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manual inference\n",
    "dummy_error_profile = np.zeros((20_000,32), dtype=\"float32\")\n",
    "error_profile_c0 = dummy_error_profile#None\n",
    "error_profile_c1 = dummy_error_profile#None\n",
    "error_profile_h0 = dummy_error_profile#None\n",
    "error_profile_op = dummy_error_profile#None\n",
    "# ERR_PARAM_TF = None\n",
    "# shuffle_order_c0 = None\n",
    "# shuffle_order_c1 = None\n",
    "# shuffle_order_h0 = None\n",
    "# shuffle_order_op = None\n",
    "\n",
    "shuffle_order_c0 = np.arange(model.get_layer(\"c0\").weights[0].shape[-1])\n",
    "shuffle_order_c1 = np.arange(model.get_layer(\"c1\").weights[0].shape[-1])\n",
    "shuffle_order_h0 = np.arange(model.get_layer(\"h0\").weights[0].shape[-1])\n",
    "shuffle_order_op = np.arange(model.get_layer(\"op\").weights[0].shape[-1])\n",
    "ERR_PARAM_TF = None\n",
    "np.random.shuffle(shuffle_order_c0)\n",
    "np.random.shuffle(shuffle_order_c1)\n",
    "np.random.shuffle(shuffle_order_h0)\n",
    "np.random.shuffle(shuffle_order_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da82242e-682e-4d79-9de3-3df2eb734147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get weights and biases from model\n",
    "c0_kernels, c0_biases = model.get_layer(\"c0\").weights\n",
    "c1_kernels, c1_biases = model.get_layer(\"c1\").weights\n",
    "h0_weights, h0_biases = model.get_layer(\"h0\").weights\n",
    "op_weights, op_biases = model.get_layer(\"op\").weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "642f0efc-2ead-47a1-9fe4-860bf84024f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b_images = images\n",
    "b_labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c4e26f1-b4b8-48d4-a06f-d7c590339cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# L0: CONVOLUTION LAYER\n",
    "## L0.A: Get dimension values\n",
    "#### kernel height, kernel width, no of channels in input image, no of filter kernels \n",
    "kr_ht, kr_wt, no_ch, no_kr = c0_kernels.shape\n",
    "\n",
    "no_im = b_images.shape[0]\n",
    "no_ch = b_images.shape[-1]\n",
    "\n",
    "assert no_im == len(b_labels)\n",
    "\n",
    "### input image dimensions\n",
    "im_ht = b_images.shape[1]\n",
    "im_wt = b_images.shape[2]\n",
    "\n",
    "### convolution layer output dimensions (padding=same)\n",
    "y_ht = im_ht\n",
    "y_wt = im_wt\n",
    "\n",
    "### patch dimensions\n",
    "no_of_patches = y_ht * y_wt\n",
    "patch_len     = kr_ht * kr_wt * no_ch\n",
    "\n",
    "## L0.B: Extract Images Patches\n",
    "patches = tf.image.extract_patches(images=b_images,\n",
    "                                 sizes=[1, kr_ht, kr_wt, 1],\n",
    "                                 strides=[1, 1, 1, 1],\n",
    "                                 rates=[1, 1, 1, 1],\n",
    "                                 padding='SAME')\n",
    "### flatten patches\n",
    "flat_patches = tf.reshape(patches, (no_im, no_of_patches, patch_len))\n",
    "### tranpose for matrix multiplication\n",
    "flat_patches = tf.transpose(flat_patches, (0,2,1))\n",
    "\n",
    "## L0.C: Flatten filter kernels\n",
    "### first reorder kernels by no. of output-kernels\n",
    "flat_kernels = tf.transpose(c0_kernels, perm=(3,0,1,2))\n",
    "### then reshape to required matrix shape\n",
    "flat_kernels = tf.reshape(flat_kernels, (no_kr, kr_ht*kr_wt*no_ch))\n",
    "\n",
    "## L0.D: Perform Matrix Multiplication\n",
    "conv_mul_out_list = []\n",
    "### for each image in batch\n",
    "for im in range(no_im):\n",
    "    single_im_patch = flat_patches[im,:,:]\n",
    "    # conv_out_list.append(tf.matmul(flat_kernels, single_im_patch))\n",
    "    BLOCK_HEIGHT = N_THREADS_PER_BLOCK # no. of threads per block\n",
    "    BLOCK_WIDTH = kr_ht*kr_wt # totcols is always (going to be) a multiple of BLOCK_WIDTH\n",
    "    BATCH_BLOCK_SIZE = 32 # user-defined: NOT the actual batch block size in this context.\n",
    "                            # simply the tile block width of matB\n",
    "    # pad matrix for good matrix shape\n",
    "    no_cols_to_pad = BATCH_BLOCK_SIZE-(single_im_patch.shape[1]%BATCH_BLOCK_SIZE)\n",
    "    paddings = tf.constant([[0, 0,], # padding above and below\n",
    "                            [0, no_cols_to_pad]]) # padding left and right\n",
    "    padded_single_im_patch = tf.pad(single_im_patch, \n",
    "                                    paddings,\n",
    "                                    mode=\"CONSTANT\", \n",
    "                                    constant_values=0.0)\n",
    "    # is shuffling required\n",
    "    if shuffle_order_c0 is not None:\n",
    "        # shuffle filter order matrix\n",
    "        shuffled_kernels = tf.gather(flat_kernels, shuffle_order_c0)\n",
    "    else:\n",
    "        shuffled_kernels = flat_kernels\n",
    "\n",
    "    # is error injection required\n",
    "    if error_profile_c0 is not None:\n",
    "        shuffled_conv_mul_out = matmul_ERR(shuffled_kernels, \n",
    "                                           padded_single_im_patch,\n",
    "                                           BLOCK_HEIGHT, \n",
    "                                           BLOCK_WIDTH, \n",
    "                                           BATCH_BLOCK_SIZE, \n",
    "                                           ERR_PROFILE=error_profile_c0,\n",
    "                                           ERR_PARAM_TF=ERR_PARAM_TF,)[:,:-no_cols_to_pad]            \n",
    "\n",
    "    else:\n",
    "        shuffled_conv_mul_out = tf.matmul(shuffled_kernels, padded_single_im_patch)[:,:-no_cols_to_pad]\n",
    "\n",
    "    # was the kernel matrix shuffled ?\n",
    "    if shuffle_order_c0 is not None:\n",
    "        # unshuffle conv_out\n",
    "        indices = tf.expand_dims(shuffle_order_c0, axis=1)\n",
    "        updates = tf.range(tf.size(indices))\n",
    "        shape = shuffle_order_c0.shape\n",
    "        scatter = tf.scatter_nd(indices, updates, shape)\n",
    "        conv_mul_out = tf.gather(shuffled_conv_mul_out, scatter)\n",
    "    else:\n",
    "        conv_mul_out = shuffled_conv_mul_out\n",
    "    conv_mul_out_list.append(conv_mul_out)\n",
    "    # this completes the matrix multiplication equivalent of convolution of *ONE* image in the batch of image\n",
    "\n",
    "conv_out = tf.stack(conv_mul_out_list)\n",
    "conv_out = tf.transpose(conv_out, (0,2,1)) # rearrange channel order\n",
    "conv_out = tf.reshape(conv_out, (no_im, y_ht,y_wt, no_kr)) # reshape to filter output shape\n",
    "\n",
    "## Add bias\n",
    "conv_out = tf.nn.bias_add(conv_out, c0_biases)\n",
    "## ReLU\n",
    "conv0_out = tf.nn.relu(conv_out)\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6e40545-e898-45d4-96ca-9f48068bf2d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0012466013>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check for layer c0\n",
    "tf.reduce_max(tf.abs(tf_c0_out-conv0_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1a1ad35-9b2a-4ce3-a4dc-26364c2aa984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# L1: MAX POOLING LAYER\n",
    "pool0_out = tf.nn.max_pool(conv0_out,\n",
    "                            ksize=[1, 2, 2, 1], #(batch_size, height, width, depth)\n",
    "                            strides=[1, 2, 2, 1], #(batch_size, height, width, depth)\n",
    "                            padding='VALID')\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "541cf385-753b-44df-a9bd-75f0d5be71a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0012466013>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check for layer p0\n",
    "tf.reduce_max(tf.abs(tf_p0_out-pool0_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a01b974-3115-4881-b341-f0016e5500f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# L2: DROPOUT LAYER (Disabled in Inference)\n",
    "# L3: CONVOLUTION LAYER\n",
    "## L3.A: Get dimension values\n",
    "#### kernel height, kernel width, no of channels in input image, no of filter kernels \n",
    "kr_ht, kr_wt, no_ch, no_kr = c1_kernels.shape\n",
    "\n",
    "no_im = pool0_out.shape[0]\n",
    "no_ch = pool0_out.shape[-1]\n",
    "\n",
    "assert no_im == len(b_labels)\n",
    "\n",
    "### input image dimensions\n",
    "im_ht = pool0_out.shape[1]\n",
    "im_wt = pool0_out.shape[2]\n",
    "\n",
    "### convolution layer output dimensions (padding=same)\n",
    "y_ht = im_ht\n",
    "y_wt = im_wt\n",
    "\n",
    "### patch dimensions\n",
    "no_of_patches = y_ht * y_wt\n",
    "patch_len     = kr_ht * kr_wt * no_ch\n",
    "\n",
    "## L3.B: Extract Images Patches\n",
    "patches = tf.image.extract_patches(images=pool0_out,\n",
    "                                 sizes=[1, kr_ht, kr_wt, 1],\n",
    "                                 strides=[1, 1, 1, 1],\n",
    "                                 rates=[1, 1, 1, 1],\n",
    "                                 padding='SAME')\n",
    "### flatten patches\n",
    "flat_patches = tf.reshape(patches, (no_im, no_of_patches, patch_len))\n",
    "### tranpose for matrix multiplication\n",
    "flat_patches = tf.transpose(flat_patches, (0,2,1))\n",
    "\n",
    "## L3.C: Flatten filter kernels\n",
    "### first reorder kernels by no. of output-kernels\n",
    "flat_kernels = tf.transpose(c1_kernels, perm=(3,0,1,2))\n",
    "### then reshape to required matrix shape\n",
    "flat_kernels = tf.reshape(flat_kernels, (no_kr, kr_ht*kr_wt*no_ch))\n",
    "\n",
    "## L3.D: Perform Matrix Multiplication\n",
    "conv_mul_out_list = []\n",
    "### for each image in batch\n",
    "for im in range(no_im):\n",
    "    single_im_patch = flat_patches[im,:,:]\n",
    "    # conv_out_list.append(tf.matmul(flat_kernels, single_im_patch))\n",
    "    BLOCK_HEIGHT = N_THREADS_PER_BLOCK # no. of threads per block\n",
    "    BLOCK_WIDTH = kr_ht*kr_wt # totcols is always (going to be) a multiple of BLOCK_WIDTH\n",
    "    BATCH_BLOCK_SIZE = 32 # user-defined: NOT the actual batch block size in this context.\n",
    "                            # simply the tile block width of matB\n",
    "    # pad matrix for good matrix shape\n",
    "    no_cols_to_pad = BATCH_BLOCK_SIZE-(single_im_patch.shape[1]%BATCH_BLOCK_SIZE)\n",
    "    paddings = tf.constant([[0, 0,], # padding above and below\n",
    "                            [0, no_cols_to_pad]]) # padding left and right\n",
    "    padded_single_im_patch = tf.pad(single_im_patch, \n",
    "                                    paddings,\n",
    "                                    mode=\"CONSTANT\", \n",
    "                                    constant_values=0.0)\n",
    "    # is shuffling required\n",
    "    if shuffle_order_c1 is not None:\n",
    "        # shuffle filter order matrix\n",
    "        shuffled_kernels = tf.gather(flat_kernels, shuffle_order_c1)\n",
    "    else:\n",
    "        shuffled_kernels = flat_kernels\n",
    "\n",
    "    # is error injection required\n",
    "    if error_profile_c1 is not None:\n",
    "        shuffled_conv_mul_out = matmul_ERR(shuffled_kernels, \n",
    "                                           padded_single_im_patch,\n",
    "                                           BLOCK_HEIGHT, \n",
    "                                           BLOCK_WIDTH, \n",
    "                                           BATCH_BLOCK_SIZE, \n",
    "                                           ERR_PROFILE=error_profile_c1,\n",
    "                                           ERR_PARAM_TF=ERR_PARAM_TF,)[:,:-no_cols_to_pad]            \n",
    "\n",
    "    else:\n",
    "        shuffled_conv_mul_out = tf.matmul(shuffled_kernels, padded_single_im_patch)[:,:-no_cols_to_pad]\n",
    "\n",
    "    # was the kernel matrix shuffled ?\n",
    "    if shuffle_order_c1 is not None:\n",
    "        # unshuffle conv_out\n",
    "        indices = tf.expand_dims(shuffle_order_c1, axis=1)\n",
    "        updates = tf.range(tf.size(indices))\n",
    "        shape = shuffle_order_c1.shape\n",
    "        scatter = tf.scatter_nd(indices, updates, shape)\n",
    "        conv_mul_out = tf.gather(shuffled_conv_mul_out, scatter)\n",
    "    else:\n",
    "        conv_mul_out = shuffled_conv_mul_out\n",
    "    conv_mul_out_list.append(conv_mul_out)\n",
    "    # this completes the matrix multiplication equivalent of convolution of *ONE* image in the batch of image\n",
    "\n",
    "conv_out = tf.stack(conv_mul_out_list)\n",
    "conv_out = tf.transpose(conv_out, (0,2,1)) # rearrange channel order\n",
    "conv_out = tf.reshape(conv_out, (no_im, y_ht,y_wt, no_kr)) # reshape to filter output shape\n",
    "\n",
    "## Add bias\n",
    "conv_out = tf.nn.bias_add(conv_out, c1_biases)\n",
    "## ReLU\n",
    "conv1_out = tf.nn.relu(conv_out)\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75cb6d2f-b6ef-4dfc-9456-85f636b71695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.005921334>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check for layer c1\n",
    "tf.reduce_max(tf.abs(tf_c1_out-conv1_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91a5f373-7f23-4184-a7c9-c05f2173bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L4: MAX POOLING LAYER\n",
    "pool1_out = tf.nn.max_pool(conv1_out,\n",
    "                            ksize=[1, 2, 2, 1], #(batch_size, height, width, depth)\n",
    "                            strides=[1, 2, 2, 1], #(batch_size, height, width, depth)\n",
    "                            padding='VALID')\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "180b11ff-1abf-45df-a240-dd3c7bd10c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0045457482>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check for layer p0\n",
    "tf.reduce_max(tf.abs(tf_p1_out-pool1_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71a5f7fe-454c-43a2-b532-e006946914cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L5: DROPOUT LAYER (Disabled in Inference)\n",
    "# L6: FLATTEN LAYER\n",
    "flat_out = tf.reshape(pool1_out, (no_im, -1) ) #[batch_size, flat_vec_size]\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22e2bddf-9063-4ba7-bc74-4030d0d7ebe5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0045457482>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check for layer flatten\n",
    "tf.reduce_max(tf.abs(tf_flatten_out-flat_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e5f3721-08e3-42fc-ab22-643aa7a0d5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# L7: HIDDEN LAYER 0\n",
    "## tranpose input vector\n",
    "h0_in = tf.transpose(flat_out, perm=[1,0]) #[flat_vec_size, batch_size]\n",
    "## transpose weight matrices\n",
    "h0_weights_tr = tf.transpose(h0_weights, perm=[1,0]) #[no_of_weights, flat_vec_size]\n",
    "\n",
    "## is shuffling required\n",
    "if shuffle_order_h0 is not None:\n",
    "    ## shuffle weight matrix\n",
    "    shuffled_weights = tf.gather(h0_weights_tr, shuffle_order_h0)\n",
    "else:\n",
    "    shuffled_weights = h0_weights_tr\n",
    "\n",
    "## is error injection required\n",
    "if error_profile_h0 is not None:\n",
    "    ## multiply with shuffled weight matrix\n",
    "    BLOCK_HEIGHT = N_THREADS_PER_BLOCK # no. of threads per block\n",
    "    BLOCK_WIDTH = 32 # totcols is always (going to be) a multiple of BLOCK_WIDTH\n",
    "    BATCH_BLOCK_SIZE = 32 # in reality, inference is always one image at a time. \n",
    "                         # However, here we are using batch inference here for speedup\n",
    "    shuffled_mult_out = matmul_ERR(shuffled_weights, \n",
    "                                   h0_in,\n",
    "                                   BLOCK_HEIGHT, \n",
    "                                   BLOCK_WIDTH, \n",
    "                                   BATCH_BLOCK_SIZE, \n",
    "                                   ERR_PROFILE=error_profile_h0,\n",
    "                                   ERR_PARAM_TF=ERR_PARAM_TF)\n",
    "else:\n",
    "    shuffled_mult_out = tf.linalg.matmul(shuffled_weights, h0_in)\n",
    "\n",
    "## was the weight matrix shuffled\n",
    "if shuffle_order_h0 is not None:\n",
    "    # unshuffle mult_out\n",
    "    indices = tf.expand_dims(shuffle_order_h0, axis=1)\n",
    "    updates = tf.range(tf.size(indices))\n",
    "    shape = shuffle_order_h0.shape\n",
    "    scatter = tf.scatter_nd(indices, updates, shape)\n",
    "    h0_mult_out = tf.gather(shuffled_mult_out, scatter)\n",
    "else:\n",
    "    h0_mult_out = shuffled_mult_out\n",
    "\n",
    "\n",
    "# Add bias\n",
    "h0_bout = tf.add(h0_mult_out, tf.expand_dims(h0_biases,axis=1))\n",
    "# RelU\n",
    "h0_out = tf.nn.relu(h0_bout)\n",
    "# h0_out needs to be transposed again in h1_in\n",
    "# so although h0_out shape is not \"standard\", we output it as it is\n",
    "\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55756f21-151f-43b0-ae26-21c84865ecd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0069750547>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check for layer h0\n",
    "tf.reduce_max(tf.abs(tf_h0_out-tf.transpose(h0_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edcbb94e-7321-424c-93d9-7fd25f8669b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L8: DROPOUT LAYER (Disabled in Inference)\n",
    "# L9: OUTPUT LAYER\n",
    "## tranpose input vector\n",
    "op_in = h0_out\n",
    "## transpose weight matrices\n",
    "op_weights_tr = tf.transpose(op_weights, perm=[1,0]) #[no_of_weights, flat_vec_size]\n",
    "\n",
    "## is shuffling required\n",
    "if shuffle_order_op is not None:\n",
    "    ## shuffle weight matrix\n",
    "    shuffled_weights = tf.gather(op_weights_tr, shuffle_order_op)\n",
    "else:\n",
    "    shuffled_weights = op_weights_tr\n",
    "\n",
    "## is error injection required\n",
    "if error_profile_op is not None:\n",
    "    ## multiply with shuffled weight matrix\n",
    "    BLOCK_HEIGHT = NO_OF_CLASSES # no. of threads per block\n",
    "    BLOCK_WIDTH = 32 # totcols is always (going to be) a multiple of BLOCK_WIDTH\n",
    "    BATCH_BLOCK_SIZE = 32 # inference is always one image at a time.\n",
    "    shuffled_mult_out = matmul_ERR(shuffled_weights, \n",
    "                                   op_in,\n",
    "                                   BLOCK_HEIGHT, \n",
    "                                   BLOCK_WIDTH, \n",
    "                                   BATCH_BLOCK_SIZE, \n",
    "                                   ERR_PROFILE=error_profile_op,\n",
    "                                   ERR_PARAM_TF=ERR_PARAM_TF)\n",
    "else:\n",
    "    shuffled_mult_out = tf.linalg.matmul(shuffled_weights, op_in)\n",
    "\n",
    "## was the weight matrix shuffled\n",
    "if shuffle_order_op is not None:\n",
    "    # unshuffle mult_out\n",
    "    indices = tf.expand_dims(shuffle_order_op, axis=1)\n",
    "    updates = tf.range(tf.size(indices))\n",
    "    shape = shuffle_order_op.shape\n",
    "    scatter = tf.scatter_nd(indices, updates, shape)\n",
    "    op_mult_out = tf.gather(shuffled_mult_out, scatter)\n",
    "else:\n",
    "    op_mult_out = shuffled_mult_out\n",
    "\n",
    "\n",
    "# Add bias\n",
    "op_bout = tf.add(op_mult_out, tf.expand_dims(op_biases,axis=1))\n",
    "# Softmax\n",
    "op_out = tf.nn.softmax(op_bout, axis=0)\n",
    "# Tranpose to standard order\n",
    "class_scores = tf.transpose(op_out, perm=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a3018d2-81cf-412e-928b-9d76de2e88ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0015574396>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check for layer op\n",
    "tf.reduce_max(tf.abs(tf_op_out-class_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deb2c02f-4ffa-4ca7-a7c9-185b3f52ce7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0015574396>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check for layer op\n",
    "tf.reduce_max(tf.abs(model(images)-class_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c593a16-fc4c-4236-a11b-dae0e375b061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=6>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions\n",
    "predictions = tf.math.argmax(class_scores, axis=1)\n",
    "## count no. of wrong predicitons\n",
    "# return predictions\n",
    "tf.math.reduce_sum(tf.cast(tf.math.not_equal(tf.cast(b_labels, dtype=tf.int64), predictions), dtype=tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73263fea-06cf-4ab9-918e-651a64e69c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_predictions = tf.math.argmax(model(images), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62d403f6-4dfc-4add-bd43-ff28e8c0cbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_predictions - predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a83fa390-831b-43df-a78d-d442294ad824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=6>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(tf.cast(tf.math.not_equal(tf.cast(b_labels, dtype=tf.int64), predictions), dtype=tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3515be0-8861-4790-8a7f-2041e0782f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=6>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(tf.cast(tf.math.not_equal(tf.cast(b_labels, dtype=tf.int64), tf_predictions), dtype=tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9bf30-cdb2-40da-b869-4fa843184abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
